# CodeSculptor

**CodeSculptor** is an experimental AI-powered development agent designed to **analyze, refactor, and extend Python projects automatically**.
It uses an OpenAI-like plannerâ€“executor loop on top of a [vLLM](https://github.com/vllm-project/vllm) backend, combining project context analysis, structured tool calls, and iterative refinement.

---
## Table of Content
- [CodeSculptor](#codesculptor)
  - [Table of Content](#table-of-content)
  - [ğŸš€ Getting Started / Usage](#-getting-started--usage)
    - [1. Clone the repository](#1-clone-the-repository)
    - [2. Install the package](#2-install-the-package)
    - [3. Set environment variables](#3-set-environment-variables)
    - [4. Run CLI commands](#4-run-cli-commands)
    - [5. Other examples](#5-other-examples)
    - [6. Workflow Overview](#6-workflow-overview)
  - [ğŸš€ Features](#-features)
  - [ğŸ“¦ Repository Structure](#-repository-structure)
  - [ğŸ‘¨â€ğŸ’» Developer Guide with DevContainer](#-developer-guide-with-devcontainer)
    - [1. DevContainer](#1-devcontainer)
    - [2. Dockerfile](#2-dockerfile)
    - [3. Python Dependencies](#3-python-dependencies)
    - [4. Start the DevContainer](#4-start-the-devcontainer)
    - [Workflow](#workflow)
  - [ğŸ› ï¸ Tools Available](#ï¸-tools-available)
  - [âš™ï¸ How It Works](#ï¸-how-it-works)
    - [ğŸ“‹ Planner Agent (Reasoning Layer)](#-planner-agent-reasoning-layer)
    - [ğŸ” Agent Loop (Execution Layer)](#-agent-loop-execution-layer)
    - [ğŸ› ï¸ Tools (Action Layer)](#ï¸-tools-action-layer)
    - [â™»ï¸ Re-Planning \& Self-Healing (Future)](#ï¸-re-planning--self-healing-future)
  - [Contributions](#contributions)
  - [ğŸ“„ License](#-license)


---

## ğŸš€ Getting Started / Usage

Follow these steps to install and use **CodeSculptor**:

### 1. Clone the repository

```bash
git clone https://github.com/Perpetue237/codesculptor.git
cd codesculptor
```

### 2. Install the package

Use editable mode to allow local changes:

```bash
pip install -e .
```

### 3. Set environment variables

CodeSculptor requires a running vLLM server. Set:

```bash
export VLLM_URL="http://localhost:8008"
export VLLM_MODEL="openai/gpt-oss-120b"
```

Adjust according to your server setup.

### 4. Run CLI commands

Generate or refactor code with `codesculptor-cli`. For example, to create a basic Dockerized FastAPI app:

```bash
codesculptor-cli ./test_project "create files for a basic dockerized FastAPI application. The initial app should just return a JSON with 'hello to the OpenAI community'"
```

This will:

* Generate a minimal FastAPI app structure.
* Create Dockerfiles for containerization.
* Initialize the project in `./test_project`.

### 5. Other examples

* Merge multiple Python modules into a single file.
* Refactor functions and automatically generate unit tests.
* Update imports across the project after refactoring.

### 6. Workflow Overview

1. `prepare_context` scans your project.
2. `PlannerAgent` outputs a structured JSON plan.
3. `AgentLoop` executes each tool step by step.
4. Tests are run automatically (existing or generated).
5. Changes are applied safely, with backups if needed.


## ğŸš€ Features

* ğŸ“‚ **Project Context Builder** â€“ Parses files, functions, classes, and imports.
* ğŸ§  **Planner Agent** â€“ Generates structured JSON plans of tool calls (no free-form text).
* ğŸ” **Agent Loop** â€“ Executes tool calls, tracks logs, and retries if needed.
* ğŸ› ï¸ **Tool Registry** â€“ Includes file creation, backup, import updates, code refactoring, and test execution.
* ğŸ§ª **Automated Testing** â€“ Runs `pytest` or generated test files before/after modifications.
* ğŸ–‹ï¸ **Code Refactoring** â€“ Uses LLM guidance with file structure hints for safer transformations.

---

## ğŸ“¦ Repository Structure

```
.
â”œâ”€â”€ main.py                # CLI entrypoint
â”œâ”€â”€ agent/                 # Core agent logic
â”‚   â”œâ”€â”€ planner.py         # PlannerAgent â†’ generates tool calls
â”‚   â”œâ”€â”€ loop.py            # AgentLoop â†’ executes plans
â”‚   â””â”€â”€ executor.py        # (reserved for future execution abstraction)
â”œâ”€â”€ llm/                   # vLLM client and prompts
â”‚   â”œâ”€â”€ client.py
â”‚   â””â”€â”€ prompts.py
â”œâ”€â”€ tools/                 # Actionable tools
â”‚   â”œâ”€â”€ prepare_context.py # Builds project context
â”‚   â”œâ”€â”€ refactor_code.py
â”‚   â”œâ”€â”€ run_tests.py
â”‚   â”œâ”€â”€ update_imports.py
â”‚   â””â”€â”€ registry.py
â”œâ”€â”€ utils/                 # Utilities
â”‚   â”œâ”€â”€ file_ops.py
â”‚   â”œâ”€â”€ logging.py
â”‚   â””â”€â”€ search.py
â”œâ”€â”€ test_project/           # Dockerized test project
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app/main.py
â””â”€â”€ tests/                  # Reserved for unit/integration tests
```

---

## ğŸ‘¨â€ğŸ’» Developer Guide with DevContainer

This repository provides a **VS Code DevContainer** for an optimized development environment with GPU support and vLLM.

### 1. DevContainer

Create `.devcontainer/devcontainer.json`:

```json
{
  "name": "gpt-oss-120b-vllm",
  "build": {
    "dockerfile": "Dockerfile"
  },
  "runArgs": [
    "--gpus", "\"device=5,6\"",
    "--shm-size=64gb",
    "--ulimit", "memlock=-1",
    "--ulimit", "stack=67108864",
    "--ipc=host"
  ],
  "containerEnv": {
    "PYTHONUNBUFFERED": "1"
  },
  "customizations": {
    "vscode": {
      "extensions": [
        "ms-python.python",
        "ms-toolsai.jupyter",
        "innerlee.nvidia-smi",
        "Leonardo16.nvidia-gpu",
        "RSIP-Vision.nvidia-smi-plus"
      ]
    }
  },
  "mounts": [
    "source=/raid/vllm,target=/app/vllm,type=bind,consistency=cached" 
  ],
  "postStartCommand": "vllm serve openai/gpt-oss-120b --gpu-memory-utilization 0.95 --tensor-parallel-size 2 --download-dir /app/vllm --port 8008"
}
```

---

### 2. Dockerfile

Create `.devcontainer/Dockerfile`:

```dockerfile
FROM vllm/vllm-openai:gptoss

ENV USERNAME="$USERNAME"
ARG DEBIAN_FRONTEND=noninteractive
ENV TZ Europe/Berlin
ENV VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1

COPY . .

RUN pip3 --no-cache-dir install -r requirements.txt
RUN apt-get update && apt-get install -y curl

EXPOSE 8008
```

---

### 3. Python Dependencies

`requirements.txt`:

```
black
pytest
commitizen
```
---

### 4. Start the DevContainer

1. Open the project in **VS Code**.
2. Click **Reopen in Container** when prompted.
3. The `postStartCommand` will automatically launch **vLLM server** on port `8008`.

---
### Workflow

1. `prepare_context` scans your project files.
2. `PlannerAgent` generates a JSON plan of tool calls.
3. `AgentLoop` executes each tool in sequence.
4. Tests run (if available or auto-generated).
5. Changes are applied safely (backup first).

---

## ğŸ› ï¸ Tools Available

* **create\_file** â†’ Create new source files.
* **backup\_file** â†’ Backup existing files before modifications.
* **update\_imports** â†’ Fix imports across files.
* **refactor\_code** â†’ Apply structured code transformations.
* **run\_tests** â†’ Execute test suite or generated tests.
* **format\_code** â†’ Run `black` to auto-format.

---

## âš™ï¸ How It Works

The CodeSculptor agent runs on an OpenAI-like plannerâ€“executor loop, designed to make structured, safe, and iterative changes to your codebase.

### ğŸ“‹ Planner Agent (Reasoning Layer)

Takes your natural language request (e.g., â€œmerge utils.py and helpers.py into one moduleâ€).

Uses the project context (functions, classes, imports) to understand the current codebase.

Produces a structured JSON plan of tool calls â€“ never free text.
Example:

json
Kopieren
Bearbeiten
{
  "action": "refactor_code",
  "args": {
    "path": "utils/helpers.py",
    "instruction": "merge into utils.py"
  }
}

### ğŸ” Agent Loop (Execution Layer)

Iterates through the planned tool calls one by one.

Ensures dependencies are respected (e.g., backup â†’ refactor â†’ update imports â†’ run tests).

Captures logs and errors for each step, with the ability to retry.

### ğŸ› ï¸ Tools (Action Layer)

The agent never edits files directly. Instead, it calls specialized tools:

backup_file â†’ snapshot before modifying.

create_file â†’ safely generate new files.

refactor_code â†’ apply structured code transformations.

update_imports â†’ keep imports consistent.

run_tests â†’ verify changes with pytest.

format_code â†’ ensure style consistency with black.

This makes the workflow transparent, reproducible, and debuggable.

### â™»ï¸ Re-Planning & Self-Healing (Future)

If a step fails (e.g., tests break), the agent will be able to re-plan automatically.

The loop can feed test results or error logs back into the Planner Agent, generating a new plan until success.

This section emphasizes the structured loop, safety-first approach, and extensibility of your agent.

``` mermaid
flowchart TD
    A[ğŸ’¬ User Request] --> B[ğŸ§  Planner Agent]
    B -->|Generates JSON Plan| C[ğŸ” Agent Loop]
    C --> D[ğŸ› ï¸ Tools]

    D -->|âœ… run_tests| D1[ğŸ§ª Run Tests]
    D <-->|ğŸ“„ create_file| D2[ğŸ“„ File Creation]
    D <-->|ğŸ–‹ï¸ refactor_code| D3[ğŸ–‹ï¸ Refactor Code]
    D <-->|ğŸ”— update_imports| D4[ğŸ”— Update Imports]
    D <-->|ğŸ¨ format_code| D5[ğŸ¨ Format Code]
    D -->|ğŸ’¾ backup_file| D6[ğŸ’¾ Backup]

    D1 -->|âŒ Tests Fail| B
    D1 -->|âœ… Tests Pass| E[ğŸ† Success]
```

---

## Contributions

*

---

## ğŸ“„ License

MIT License. See [LICENSE](LICENSE) for details.
